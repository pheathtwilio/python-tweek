<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Super Simple Video Test Harness</title>
  <style>
    :root {
      --border:#e5e7eb; --muted:#64748b; --bg:#ffffff; --chip:#f1f5f9;
    }
    * { box-sizing: border-box; }
    body { margin: 0; font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif; background: var(--bg); }
    .app { display: grid; grid-template-columns: 340px 1fr; min-height: 100vh; }
    .left { border-right: 1px solid var(--border); padding: 20px; display: flex; flex-direction: column; gap: 16px; }
    .right { padding: 20px; }
    h1 { margin: 0 0 8px; font-size: 18px; }
    .row { display: flex; flex-wrap: wrap; gap: 10px; align-items: center; }
    button { padding: 10px 14px; border-radius: 8px; border: 1px solid #cbd5e1; background: white; cursor: pointer; }
    button:disabled { opacity: .5; cursor: default; }
    label { font-size: 12px; color: var(--muted); display:block; }
    input[type=text] { width: 100%; padding: 8px; border:1px solid var(--border); border-radius: 8px; }
    .fields { display: grid; gap: 12px; grid-template-columns: 1fr 1fr; }
    .field { display:flex; flex-direction:column; gap:6px; }
    .card { border:1px solid var(--border); border-radius: 12px; padding: 12px; background: #fff; }
    .badge { display:inline-block; padding:2px 8px; border-radius:999px; background: var(--chip); border:1px solid var(--border); font-size:12px; }
    pre#serverLog { height: 180px; overflow:auto; margin:0; background:#f8fafc; border-radius:8px; padding:8px; border:1px solid var(--border); }
    /* Participants grid */
    #participants { 
      display: grid;
      grid-template-columns: repeat(2, 1fr); /* 2 per row */
      gap: 16px; /* spacing between tiles */
      width: 100%;
      /*max-width: 1200px; /* optional: keeps it from stretching too wide */
      margin: 0 auto; /* center in page */
      padding: 16px;
      box-sizing: border-box;
    }
    .tile {
      /*background: #111;       /* optional: dark background */
      border-radius: 12px;
      overflow: hidden;
      /*display: flex;
      flex-direction: column;*/
      align-items: center;
      justify-content: center;
    }
    .tile .media { position: relative; width: 60%; background:#000; }
    .tile video, .tile img {
      width: 100%;
      height: auto;
      max-height: 400px;   /* keeps them nicely scaled */
      object-fit: cover;   /* crop nicely if aspect ratio differs */
      border-radius: 12px;
    }
    .tile canvas.overlay { position:absolute; left:0; top:0; width:100%; height:100%; pointer-events:none; }
    .tile .meta { width: 40%; border-left:1px solid var(--border); padding: 10px; display:flex; flex-direction:column; gap:6px; }
    .kvs { font-size: 12px; color:#0f172a; }
    .kv { display:flex; justify-content: space-between; gap:8px; font-size: 12px; }
    .kv .k { color: var(--muted); }
    .kv .v { font-weight: 600; }
    /* Hidden preview video used for local capture only */
    video#preview { 
      position: absolute;
      left: -9999px;
      top: 0;
      width: 640px;   /* optional */
      height: auto;   /* optional */
      opacity: 0;     /* or visibility:hidden */
      pointer-events: none;
    }
    @media (max-width: 920px) {
      .app { grid-template-columns: 1fr; }
      .left { border-right: 0; border-bottom:1px solid var(--border); }
    }
  </style>
</head>
<body>
  <div class="app">
    <!-- Left pane: controls and logs -->
    <aside class="left">
      <div>
        <h1>Controls</h1>
        <div class="row" style="margin-top:6px;">
          <button id="btnStart">Start</button>
          <button id="btnStop" disabled>Stop</button>
          <button id="btnMute" disabled>Mute Audio</button>
          <button id="btnHide" disabled>Hide Video</button>
          <span id="statusBadge" class="badge">idle</span>
        </div>
      </div>

      <div class="card">
        <div class="field">
          <label for="sessionId">Session ID</label>
          <input id="sessionId" type="text" placeholder="auto-generated…" />
        </div>
        <div class="fields" style="margin-top:10px;">
          <div class="field">
            <label for="audioLen">Audio chunk (ms)</label>
            <input id="audioLen" type="text" value="1000" />
          </div>
          <div class="field">
            <label for="videoLen">Video chunk (ms)</label>
            <input id="videoLen" type="text" value="1000" />
          </div>
        </div>
      </div>

      <div>
        <h1>Server messages</h1>
        <pre id="serverLog">Waiting…
</pre>
      </div>

      <video id="preview" autoplay playsinline muted></video>
    </aside>

    <main class="right">
      <h1>Participants</h1>
      <div id="participants"></div>
    </main>
  </div>

  <!-- Twilio Video SDK (v2.32.1) -->
  <script src="https://sdk.twilio.com/js/video/releases/2.32.1/twilio-video.min.js"></script>
  <script src="/static/messages.js"></script>
  <script>

    const serverBase = "";

    let localAudioTrack, localVideoTrack;
    let audioRecorder, videoRecorder;
    let audioStream, videoStream;
    let isMuted = false, isHidden = false;

    const snapCanvas = document.createElement('canvas');
    let snapshotTimer = null;
    const SNAPSHOT_INTERVAL_MS = 1000; // 1 fps; tune as needed

    let ws;

    // DOM helpers
    const $ = (id) => document.getElementById(id);
    const btnStart = $("btnStart"), btnStop = $("btnStop"), btnMute = $("btnMute"), btnHide = $("btnHide");
    const statusBadge = $("statusBadge"), sessionIdInput = $("sessionId");
    const audioLenInput = $("audioLen"), videoLenInput = $("videoLen");
    const serverLog = $("serverLog");
    const preview = $("preview");
    const participantsGrid = $("participants");

    const uuid = () => {
      return ([1e7]+-1e3+-4e3+-8e3+-1e11).replace(/[018]/g,c=>
        (c ^ crypto.getRandomValues(new Uint8Array(1))[0] & 15 >> c / 4).toString(16)
      );
    };
    if (!sessionIdInput.value) sessionIdInput.value = uuid();

    const setStatus = (t) => { statusBadge.textContent = t; }
    const log = (msg) => {
      const ts = new Date().toISOString().split("T")[1].replace("Z","");
      serverLog.textContent += `[${ts}] ${msg}\n`;
      serverLog.scrollTop = serverLog.scrollHeight;
    };
    const logServer = log;

    // Web Workers
    const workerUrl = new URL('/static/analytics.worker.js', window.location.origin);
    const analyticsWorker = new Worker(workerUrl);

    analyticsWorker.onmessage = (e) => {
      switch(e.data.type){
        case MSG.SNAPSHOT_OK:
          logServer(e.data.message);
          break;
        case MSG.SNAPSHOT_ERROR:
          logServer(e.data.error);
        default:
          break;
      }
    };


    // Participants
    const participants = new Map(); 

    const ensureParticipantTile = (sid) => {

      if (participants.has(sid)) return participants.get(sid);

      const tile = document.createElement("div");
      tile.className = "tile";

      const media = document.createElement("div");
      media.className = "media";

      const video = document.createElement("video");
      video.autoplay = true; video.playsInline = true; video.muted = sid === sessionIdInput.value;

      const canvas = document.createElement("canvas");
      canvas.className = "overlay";

      const meta = document.createElement("div");
      meta.className = "meta";

      media.appendChild(video);
      media.appendChild(canvas);
      tile.appendChild(media);
      tile.appendChild(meta);
      participantsGrid.appendChild(tile);

      let offscreen = null;
      let offscreenOk = false;
      if (typeof canvas.transferControlToOffscreen === "function") {
        try {
          offscreen = canvas.transferControlToOffscreen();
          offscreenOk = !!offscreen;
        } catch (e) {
          console.warn("transferControlToOffscreen failed:", e);
        }
      }

      if(offscreenOk) {

        analyticsWorker.postMessage({
          type: MSG.REGISTER_CANVAS,
          sid, 
          canvas: offscreen,
          cssWidth: 0,
          cssHeight: 0
        }, [offscreen]);

        // keep the canvas sized with the video
        const resizeObserver = new ResizeObserver(entries => {
          for (const entry of entries) {
            const cr = entry.contentRect;
            analyticsWorker.postMessage({
              type: MSG.RESIZE_CANVAS,
              sid,
              cssWidth: cr.width,
              cssHeight: cr.height
            });
          }
        });
        resizeObserver.observe(video);

        const entry = { el: tile, video, canvas, metaBox: meta, resizeObserver: resizeObserver };
        participants.set(sid, entry);
        
      }else{
        const ctx = canvas.getContext("2d");
        participants.set(sid, { el: tile, video, canvas, ctx, metaBox: meta, resizeObserver: null, offscreen: false });
        console.warn("OffscreenCanvas not available; using main-thread canvas fallback for", sid);
      }
      
      return participants.get(sid);
    };

    const attachLocalVideoToTile = (sid) => {
      const p = ensureParticipantTile(sid);
      p.video.srcObject = preview.srcObject || null;
      p.video.addEventListener("loadedmetadata", () => {
        const rect = p.video.getBoundingClientRect();
        analyticsWorker.postMessage({
          type: MSG.RESIZE_CANVAS,
          sid,
          cssWidth: rect.width,
          cssHeight: rect.height
        });
      }, { once: true });
    };

    const postFrameForEmotion = async (sid) => {

      if (!preview) return;
      if (!preview.videoWidth) return;

      if ('requestVideoFrameCallback' in preview) {
        await new Promise(res => preview.requestVideoFrameCallback(() => res()));
      }

      const bitmap = await createImageBitmap(preview);
      analyticsWorker.postMessage({ type: MSG.SNAPSHOT_REQUEST, sid, bitmap }, [bitmap]);

    };

    const waitForVideoReady = (video) => {
      return new Promise(resolve => {
        if (video.readyState >= 2 && video.videoWidth) return resolve();
        const onReady = () => {
          if (video.videoWidth) {
            video.removeEventListener('loadedmetadata', onReady);
            video.removeEventListener('playing', onReady);
            resolve();
          }
        };
        video.addEventListener('loadedmetadata', onReady, { once: true });
        video.addEventListener('playing', onReady, { once: true });
      });
    }

    const startSnapshots = (sid, intervalMs = SNAPSHOT_INTERVAL_MS) => {
      if (snapshotTimer) return;
      snapshotTimer = setInterval(() => postFrameForEmotion(sid), intervalMs);
    }
    const stopSnapshots = () => {
      if (snapshotTimer) clearInterval(snapshotTimer);
      snapshotTimer = null;
    }

    // Drawing helpers
    const drawFaceOverlays = (psid, faceDetails) => {

      try{
        analyticsWorker.postMessage({
          type: MSG.DRAW_OVERLAYS,
          sid: psid,
          faceDetails: faceDetails
        });
      }catch(e){
        console.error(`postMessage failed: ${e}`);
      }
      
    }

    const updateMetaBox = (p, faceDetails, primaryEmotion) => {
      const faces = faceDetails || [];
      if (!faces.length) {
        p.metaBox.innerHTML = '<div class="kvs">No face detected</div>';
        return;
      }
      const f = faces.sort((a,b)=>{
        const aa=(a.BoundingBox?.Width||0)*(a.BoundingBox?.Height||0);
        const bb=(b.BoundingBox?.Width||0)*(b.BoundingBox?.Height||0);
        return bb-aa;
      })[0];

      const age = f.AgeRange ? `${f.AgeRange.Low}–${f.AgeRange.High}` : "—";
      const smile = f.Smile?.Value;
      const gender = f.Gender?.Value;
      let emo = "—";
      if (f.Emotions && f.Emotions.length) {
        const sorted = [...f.Emotions].sort((a,b)=> (b.Confidence||0)-(a.Confidence||0));
        emo = sorted[0].Type || "—";
      }
      const occluded = (f.FaceOccluded && typeof f.FaceOccluded.Value === "boolean") ? String(f.FaceOccluded.Value) : "—";
      const beard = f.Beard?.Value;
      const eyesOpen = f.EyesOpen?.Value;
      const mouthOpen = f.MouthOpen?.Value;

      p.metaBox.innerHTML = `
        <div class="kvs">
          <div class="kv"><span class="k">Age Range</span><span class="v">${age}</span></div>
          <div class="kv"><span class="k">Gender</span><span class="v">${gender}</span></div>
          <div class="kv"><span class="k">Smile</span><span class="v">${smile}</span></div>
          <div class="kv"><span class="k">Emotion</span><span class="v">${emo}</span></div>
          <div class="kv"><span class="k">FaceOccluded</span><span class="v">${occluded}</span></div>
          <div class="kv"><span class="k">Beard</span><span class="v">${beard}</span></div>
          <div class="kv"><span class="k">Eyes Open</span><span class="v">${eyesOpen}</span></div>
          <div class="kv"><span class="k">Mouth Open</span><span class="v">${mouthOpen}</span></div>
        </div>
      `;
    }

    const connectWS = (sid) => {
      const proto = location.protocol === "https:" ? "wss" : "ws";
      ws = new WebSocket(`${proto}://${location.host}/ws?sid=${encodeURIComponent(sid)}`);
      ws.onopen = () => log(`WS connected as ${sid}`);
      ws.onmessage = (event) => {
        try {
          const data = JSON.parse(event.data);

          if (data.type === "emotion_result") {
            const psid = data.sid || sid;
            const p = ensureParticipantTile(psid);
            drawFaceOverlays(psid, data.faceDetails || data.FaceDetails || []);
            updateMetaBox(p, data.faceDetails || data.FaceDetails || [], data.primaryEmotion);
          } else if (data.type === "emotion_error") {
            log(`Rekognition error: ${data.message}`);
          } else {
            log(String(event.data));
          }
        } catch {
          log(String(event.data));
        }
      };
      ws.onclose = () => log("WS closed");
      ws.onerror = () => log("WS error");
    }

    const uploadChunk = async (blob, url) => {
      try {
        const fd = new FormData();
        fd.append("chunk", blob, `part-${Date.now()}.webm`);
        await fetch(url, { method: "POST", body: fd });
      } catch (err) {
        log("Upload failed");
        console.error("Upload failed:", err);
      }
    }

    const start = async () => {
      try {
        btnStart.disabled = true; setStatus("starting…");

        const sid = sessionIdInput.value || uuid();
        sessionIdInput.value = sid;
        connectWS(sid);

        const tracks = await Twilio.Video.createLocalTracks({
          audio: true,
          video: { width: 1280, height: 720, frameRate: 30 }
        });
        localAudioTrack = tracks.find(t=>t.kind==="audio");
        localVideoTrack = tracks.find(t=>t.kind==="video");

        const previewStream = new MediaStream();
        if (localAudioTrack) previewStream.addTrack(localAudioTrack.mediaStreamTrack);
        if (localVideoTrack) previewStream.addTrack(localVideoTrack.mediaStreamTrack);
        preview.srcObject = previewStream;
        preview.muted = true; 
        preview.play().catch(()=>{ /* ignore if already playing */ });

        attachLocalVideoToTile(sid);

        audioStream = new MediaStream([localAudioTrack.mediaStreamTrack]);
        videoStream = new MediaStream([localVideoTrack.mediaStreamTrack]);

        const audioMime = 'audio/webm;codecs=opus';
        const videoMime = 'video/webm;codecs=vp8';
        audioRecorder = new MediaRecorder(audioStream, { mimeType: audioMime });
        videoRecorder = new MediaRecorder(videoStream, { mimeType: videoMime });

        const audioChunkMs = Math.max(200, parseInt(audioLenInput.value || "1000", 10));
        const videoChunkMs = Math.max(200, parseInt(videoLenInput.value || "1000", 10));

        audioRecorder.ondataavailable = (e) => {
          if (e.data && e.data.size) {
            uploadChunk(e.data, `${serverBase}/upload/audio?sid=${encodeURIComponent(sid)}`);
          }
        };
        videoRecorder.ondataavailable = (e) => {
          if (e.data && e.data.size) {
            uploadChunk(e.data, `${serverBase}/upload/video?sid=${encodeURIComponent(sid)}`);
          }
        };

        audioRecorder.start(audioChunkMs);
        videoRecorder.start(videoChunkMs);

        await waitForVideoReady(preview);
        startSnapshots(sid, SNAPSHOT_INTERVAL_MS);

        btnStop.disabled = false; btnMute.disabled = false; btnHide.disabled = false;
        setStatus("streaming");
      } catch (err) {
        console.error(err); log("Start failed");
        btnStart.disabled = false; setStatus("idle");
      }
    }

    const stop = async () => {

      stopSnapshots();

      [audioRecorder, videoRecorder].forEach(r=>{ if (r && r.state!=="inactive") r.stop(); });
      [localAudioTrack, localVideoTrack].forEach(t=> t && t.stop());
      if (preview.srcObject) {
        preview.srcObject.getTracks().forEach(tr=>tr.stop());
        preview.srcObject = null;
      }
      btnStart.disabled = false; btnStop.disabled = true; btnMute.disabled = true; btnHide.disabled = true;
      isMuted=false; isHidden=false; btnMute.textContent="Mute Audio"; btnHide.textContent="Hide Video";
      setStatus("idle");
    }

    const toggleMute = () => {
      if (!localAudioTrack) return;
      isMuted = !isMuted;
      localAudioTrack.enable(!isMuted);
      btnMute.textContent = isMuted ? "Unmute Audio" : "Mute Audio";
    }

    const toggleHide = () => {
      if (!localVideoTrack) return;
      isHidden = !isHidden;
      localVideoTrack.enable(!isHidden);
      btnHide.textContent = isHidden ? "Show Video" : "Hide Video";
    }

    btnStart.onclick = start;
    btnStop.onclick = stop;
    btnMute.onclick = toggleMute;
    btnHide.onclick = toggleHide;
  </script>
</body>
</html>
